Relevant data and code can be found under the unanswerable_qa directory.

To recreate, first clone or download: https://github.com/vsuthichai/paraphraser/tree/master . I structured the project as: data_gen-->models-->paraphraser-->paraphraser and will refer to these file paths throughout the rest of these notes.

Download the pre-trained model and extract the checkpoint files. The location is arbitrary as it will just be passed in as a sys arg when running the modified inference script. I staged the pre-trained model checkpoint files under data_gen-->models-->paraphraser-->trained_model_checkpoints-->train-20180325-001253

Next we need to download the Paraphrastic Sentence (para-nmt) Embeddings. Create a new directory directly under data_gen-->models-->paraphraser named para-nmt-50m. Download the embeddings from (https://drive.google.com/u/0/uc?id=1l2liCZqWX3EfYpzv9OmVatJAEISPFihW&export=download) and extract them in this newly created directory.

Due to outdated API and non-backwards compatibility of tensorflow, we will need to install some specific tool chains in order to get this model running. To isolate the toolchain from the other models, start by creating a new virtual environment by choosing a Python interpreter and making a .\venv directory to hold it. For example: C:\Users\nickg\Documents\cse576\project\data_gen\models\paraphraser>python -m venv --system-site-packages paraphraser_venv

Activate the virtual environment: C:\Users\nickg\Documents\cse576\project\data_gen\models\paraphraser>paraphraser_venv\Scripts\activate

Navigate to paraphraser root. (i.e. cd C:\Users\nickg\Documents\cse576\project\data_gen\models\paraphraser) Install python 3.6, I specifically used Python 3.6.8 Install tensorflow, spacy, and download the engligh language model for spacy: pip install --upgrade tensorflow==1.4.0 pip install spacy python -m spacy download en

Run the modified inference python script, using the checkpoint files to load the trained model: In data_gen/models/paraphraser/paraphraser/python, run python inference.py <path_to_trained_model_checkpoint> For example: python inference.py --checkpoint=C:\Users\nickg\Documents\cse576\project\data_gen\models\paraphraser\trained_model_checkpoints\train-20180325-001253\model-171856

The original script from the paraphraser model repo takes input from the command line and generates a fixed number of paraphrases at a fixed sampling temperature interactively. For our purposes, I built custom data handlers that loads and stages the parsed (question, context, answer-list) triplets of our datasets. For each data source, thre are methods which are used to determine the subspan to paraphrase for each element in the triplet. The data handler then handles generating the subspan paraphrases accordingly for each QA entity in the parsed dataset. Parsed datasets can be found in the data_gen/datasets directory.

Currently, there is a gap in the research community concerning multiple choice datasets that incorporate unanswerable questions. In fact, the vast majority of the publicly available datasets currently do not contain unanswerable questions, and the few that do are mostly developed for Extractive QA tasks. The one exception to this norm is in the CosmosQA dataset, where roughly 6.7% of the questions are unanswerable. Parsing for these questions can be found in the data_gen/datasets/cosmos_qa directory. Another multiple choice dataset that has unanswerable questions is the ComQA dataset, however since this dataset was developed for open domain question answering and lacks context paragraphs, it has not been included at this stage of the project. More research would be needed on how to best leverage information retrieval systems to create relevant context paragraphs for this dataset. Finally, SQUAD 2.0, the canonical dataset for unanswerable questions and the one that popularized the use of them in the QA and RC research community, was developed for extractive QA tasks, and thus doesn't contain a list of multiple answer choices, making it unusable as-is for our multiple choice question dataset. However, recent work in distractor generation (the generation of artificial answer choices in MCQ generation) seems to be a promising approach that could be leveraged to create multiple choice questions from this dataset by generating distractors (plausible answers) given context-question pairs. Towards this end, and to enable the use of SQUAD 2.0 unanswerable questions in our synthetic dataset generation process, several recent systems for distrator generation were considered, which can be found in the data_gen/models directory. These systems are then used with the pre-processed and parsed unanswerable questions from SQUAD 2.0 in order create an augmented set of multiple choice questions that comply to our format. These questions are then consumed by the custom squad data handler, which is used to generate subspan paraphrases of the dataset.

A combined subsample of around 10k unanswerable questions resulting from these processes can be found in data_gen/datasets/unanswerable_qa.json
